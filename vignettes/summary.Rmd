---
title: "wundr Package Summary"
author: "John Marin, Matthew Schumwinger, Stefan Zohren"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{wundr Package Summary}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

    output:
      rmarkdown::html_vignette:
        fig_caption: yes
---

```{r, echo = FALSE}
library(wundr)
```

Package **wundr** provides API interfaces to Personal Weather Station (PWS) data 
maintained by Weather Underground (wunderground.com). Tables of PWS
locations and metadata for user specified geographic areas are constructed.
Robust retrieval of current and historical weather condition data for
selected PWS. Computational tools for spatial analysis, including Kriging
(Gaussian processes) for interpolation, as well as prediction of missing
data and forecasts. Visualization of microclimate data methods including
contextual static and interactive web maps. Additional facility to export data 
to CartoDB's spatial database hosting and webmap publishing platform.

Package **wundr** has the following functionalities:

## Creation of S4-Class Table describing a given region's PWS 

## Subsettable tables based on #1

Graphicly subset PWS.class objects by drawing a poylgon around PWS points
plotted in graphics device. *Note: this is interactive, so must be run run from 
the console.*
```{r, fig.show='hold', warning = FALSE, message = FALSE, eval = FALSE}
my_subset  <-  draw_subset(PWS.Conds.Chicago)
```

## Web retrieval of data and storage in memory

## Visualization of microclimate data

Simple plots of PWS for exploratory analysis:

```{r, fig.show='hold', warning = FALSE, message = FALSE, include = TRUE}
simple_pnts(PWS.Conds.Chicago, "Downtown Chicago PWS")
simple_density(PWS.Conds.Chicago, "Downtown Chicago PWS")
```

Contextual mapping of PWS for exploratory analysis:

```{r, fig.show='hold', warning = FALSE, message = FALSE, include = TRUE}
basemap <- set_basemap(PWS.Conds.Chicago, zoom = 12)
gg_points(PWS.Conds.Chicago, basemap, title = "Downtown Chicago PWS")
```







## Computational tools for temporal and spatial analysis

The package includes a number of computational facilities, which are devided in temporal and spatial analysis. We first discuss the **temporal analysis** using time series techniques. The functions discussed below take as inputs data.frames with historical weather data as obtained through `PWS.History` or the underlying low-level API function `PWS_history`. The first step is to select data from those data.frames and convert it into time series objects. Since the data obtained from the weather stations is irregular we have to use a package which supports **irregular time-series** (such as `zoo`). Our funciton `history_zoo` takes a historical data frame, subsets it to select data from a given station and a number of variables and creates a time series object of class `zoo`. Here is an example:

```{r, eval=FALSE}
hist.zoo <- history_zoo(Rio_history,"IRIODEJA53",c("hum","tempm"))
plot(hist.zoo,col='red', main = "Humidity and Temperatur")
```

The plot is shown below (left). We can also transform irregular time-series into **regular time-series**, this is done internally in the function `history_ts`, which works as `history_zoo`, but transforms the output to an object of class `ts`. Having a regular time-series is important for analysis and forecasting, since many models rely on this assumption. We provide a function `history_forecast` which fits an **exponential smoothing state space model (ETS)** and makes forecasts using this. The fitting procedure is based on the `forecast` package. The advantage of the (ETS) model is that it allows for good fits to seasonal data, as we encouter here. We can fit a model and produce a plot of the forcast with confidence intervals as follows (see right plot below).

```{r, eval=FALSE}
hist.ts <- history_ts(Rio_history,"IRIODEJA53","hum")
hist.forecast <- history_forecast(hist.ts)
plot(hist.forecast, main = 'Forecast', xlab='Time (days)', ylab='Humidity (%)')
```

```{r, fig.show='hold', echo=FALSE}
hist.zoo <- history_zoo(Rio_history,"IRIODEJA53",c("hum","tempm"))
plot(hist.zoo,col='red', main = "Humidity and Temperatur")
hist.ts <- history_ts(Rio_history,"IRIODEJA53","hum")
hist.forecast <- history_forecast(hist.ts)
plot(hist.forecast, main = 'Forecast', xlab='Time (days)', ylab='Humidity (%)')
```

The second part of the computational toolkit is **spatial analysis**. Popular models for spatial predictions and interpolations are **Gaussian Processes (GPs)**, which in spatial statistics are also known as **Kriging**. The kenerel underlying the GP induces spatial correlation between points. We can make predictions by calculating the posterior distribution over a new point. To do so we first select a variable from a data.frame containing weather conditions and create an object of class `geodata`  
```{r }
data.geo <- create_geo_cond(Rio_conditions,"temp_c")
```
The GP is fitted using our function `GP_fit` which itself is based on the package `geoR`. Internally, in `GP_fit` we create a grid of points to make predictions on. This is done using our function `create_grid`. A GP is then fitted and the predictions on the grid plotted as follows
```{r ,eval=FALSE}
model<-GP_fit(data.geo)
ggplot2::ggplot(data = model, ggplot2::aes(x=lon, y=lat)) +
  ggplot2::geom_tile(ggplot2::aes(fill = value),colour = "white") +
  ggplot2::scale_fill_gradient(low = "yellow", high = "red") +
  ggplot2::geom_point(data=Rio_metadata$PWSmetadata,col='black')
```

```{r ,echo=FALSE, results='hide' , warning=FALSE, comment=FALSE}
model<-GP_fit(data.geo)
ggplot2::ggplot(data = model, ggplot2::aes(x=lon, y=lat)) +
  ggplot2::geom_tile(ggplot2::aes(fill = value),colour = "white") +
  ggplot2::scale_fill_gradient(low = "yellow", high = "red") +
  ggplot2::geom_point(data=Rio_metadata$PWSmetadata,col='black')
```

Those results can then be used in more advanced visualisations. We predented a basic computational analysis toolkit. In future updates it would be intersting to include Gaussian Processes analysis for time series, as well as a combined spatio-temporal analysis, which could be visualised using antimated spatial visualisations.







## Web interface with interactive Visuals
For explanitory purposes, the user can also create interactive web maps powered 
by leaflet.js. Here, PWS locations are plotted. Station specific data can 
also be retrieved via interactive pop-ups. (click on a station)

```{r, fig.show='hold'}
webmap_pnts(PWS.Conds.Chicago)
```

Raster images can also be sent to the interactive map. Below, a simple 
density (heatmap) of PWS locations.

```{r}
webmap_raster(PWS.Conds.Chicago)
```

## Integration with the CartoDB platform  
**wundr** also contains functions that interface with the CartoDB SQL API
(http://docs.cartodb.com/cartodb-platform/sql-api/). This allows users to exploit the robust PostGIS spatial database and web publishing services of CartoDB.  

*(note: these code chunks cannot evaluated using knitr, but you can run from console with your own account and key)*

Here, we export Downtown Chicago Weather Underground PWS data to CartoDB's:  

```{r, eval = FALSE}
matt.cdb.key <- "f09ad502b34fa4096a62ea306b4650337d41009c"
matt.cdb.account <- "biglakedata"
pizza <- PWS.Conds.Chicago
r2cdb(matt.cdb.key, matt.cdb.account, pizza)
```
You can view this map here: https://biglakedata.cartodb.com/tables/pizza/map 

This interface goes both ways; we can also import spatial SQL tables into R data frame objects. 

```{r, eval=FALSE}
# matt_cdb_table <- get_cdb_table("condTest", matt.cdb.account)
head(matt_cdb_table$rows[ , c("cartodb_id", "station_id", "temperature_string", 
                              "dewpoint_string")])# pulled from presaved data file
```

